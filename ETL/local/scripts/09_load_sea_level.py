"""
SKALA Physical Risk AI System - í•´ìˆ˜ë©´ ìƒìŠ¹ ë°ì´í„° ì ì¬
NetCDF íŒŒì¼ì—ì„œ í•´ìˆ˜ë©´ ìƒìŠ¹ ì˜ˆì¸¡ ë°ì´í„°ë¥¼ ë¡œë“œ

ë°ì´í„° ì†ŒìŠ¤: sea_level_rise/*.nc
ëŒ€ìƒ í…Œì´ë¸”: sea_level_grid, sea_level_data
ì˜ˆìƒ ë°ì´í„°: ì•½ 7,000ê°œ ë ˆì½”ë“œ

ìµœì¢… ìˆ˜ì •ì¼: 2025-12-02
"""

import sys
from pathlib import Path
from tqdm import tqdm
import numpy as np

from utils import setup_logging, get_db_connection, get_data_dir, table_exists, get_row_count


def load_sea_level() -> None:
    """í•´ìˆ˜ë©´ ìƒìŠ¹ ë°ì´í„°ë¥¼ í…Œì´ë¸”ì— ë¡œë“œ"""
    logger = setup_logging("load_sea_level")
    logger.info("=" * 60)
    logger.info("í•´ìˆ˜ë©´ ìƒìŠ¹ ë°ì´í„° ë¡œë”© ì‹œì‘")
    logger.info("=" * 60)

    try:
        import netCDF4 as nc
    except ImportError:
        logger.error("âŒ netCDF4 ëª¨ë“ˆì´ í•„ìš”í•©ë‹ˆë‹¤")
        sys.exit(1)

    try:
        conn = get_db_connection()
        logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        sys.exit(1)

    cursor = conn.cursor()

    # ë°ì´í„° íŒŒì¼ ì°¾ê¸°
    data_dir = get_data_dir()
    sea_level_dir = data_dir / "sea_level_rise"

    if not sea_level_dir.exists():
        logger.error(f"âŒ sea_level_rise ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        conn.close()
        sys.exit(1)

    nc_files = list(sea_level_dir.glob("*annual_mean*.nc"))
    logger.info(f"ğŸ“‚ {len(nc_files)}ê°œ NetCDF íŒŒì¼ ë°œê²¬")

    if not nc_files:
        logger.warning("âš ï¸  NetCDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        conn.close()
        return

    # sea_level_grid í…Œì´ë¸” ì´ˆê¸°í™”
    cursor.execute("TRUNCATE TABLE sea_level_grid CASCADE")
    conn.commit()

    # ì²« ë²ˆì§¸ íŒŒì¼ì—ì„œ ê·¸ë¦¬ë“œ ì¢Œí‘œ ì¶”ì¶œ
    ds = nc.Dataset(nc_files[0])
    logger.info(f"   ë³€ìˆ˜: {list(ds.variables.keys())}")

    lat = ds.variables['latitude'][:]  # 2D ë°°ì—´ì¼ ìˆ˜ ìˆìŒ
    lon = ds.variables['longitude'][:]

    # 1Dë¡œ ë³€í™˜
    if len(lat.shape) == 2:
        lat_1d = lat[:, 0]
        lon_1d = lon[0, :]
    else:
        lat_1d = lat
        lon_1d = lon

    logger.info(f"   ê·¸ë¦¬ë“œ: {len(lat_1d)} x {len(lon_1d)}")

    # sea_level_gridì— í¬ì¸íŠ¸ ì‚½ì…
    grid_map = {}  # (j, i) -> grid_id

    for j in range(len(lat_1d)):
        for i in range(len(lon_1d)):
            if len(lat.shape) == 2:
                lat_val = float(lat[j, i])
                lon_val = float(lon[j, i])
            else:
                lat_val = float(lat_1d[j])
                lon_val = float(lon_1d[i])

            cursor.execute("""
                INSERT INTO sea_level_grid (longitude, latitude, geom)
                VALUES (%s, %s, ST_SetSRID(ST_MakePoint(%s, %s), 4326))
                RETURNING grid_id
            """, (lon_val, lat_val, lon_val, lat_val))
            grid_id = cursor.fetchone()[0]
            grid_map[(j, i)] = grid_id

    conn.commit()
    logger.info(f"   âœ… sea_level_grid: {len(grid_map)}ê°œ í¬ì¸íŠ¸")

    ds.close()

    # SSPë³„ í•´ìˆ˜ë©´ ë°ì´í„° ë¡œë“œ
    ssp_mapping = {
        'ssp1_2_6': 'ssp1',
        'ssp2_4_5': 'ssp2',
        'ssp3_7_0': 'ssp3',
        'ssp5_8_5': 'ssp5',
    }

    total_insert = 0

    for nc_file in tqdm(nc_files, desc="í•´ìˆ˜ë©´ ë°ì´í„° ë¡œë”©"):
        # SSP ì‹ë³„
        ssp_col = None
        for ssp_key, col_name in ssp_mapping.items():
            if ssp_key in nc_file.name:
                ssp_col = col_name
                break

        if not ssp_col:
            continue

        try:
            ds = nc.Dataset(nc_file)

            # ë°ì´í„° ë³€ìˆ˜ ì°¾ê¸°
            slr_var = None
            for var in ds.variables.keys():
                if 'slr' in var.lower():
                    slr_var = var
                    break

            if not slr_var:
                ds.close()
                continue

            slr_data = ds.variables[slr_var][:]  # (time, j, i)
            time_steps = slr_data.shape[0]

            # sea_level_data í…Œì´ë¸” ì´ˆê¸°í™” (ì²« ë²ˆì§¸ SSPì—ì„œë§Œ)
            if ssp_col == 'ssp1':
                cursor.execute("TRUNCATE TABLE sea_level_data")
                conn.commit()

            insert_count = 0

            for t_idx in range(time_steps):
                year = 2015 + t_idx  # ë°ì´í„° ì‹œì‘ ì—°ë„

                for (j, i), grid_id in grid_map.items():
                    val = slr_data[t_idx, j, i]
                    if np.ma.is_masked(val) or np.isnan(val):
                        continue

                    if ssp_col == 'ssp1':
                        cursor.execute("""
                            INSERT INTO sea_level_data (grid_id, year, ssp1)
                            VALUES (%s, %s, %s)
                        """, (grid_id, year, float(val)))
                    else:
                        cursor.execute(f"""
                            UPDATE sea_level_data
                            SET {ssp_col} = %s
                            WHERE grid_id = %s AND year = %s
                        """, (float(val), grid_id, year))

                    insert_count += 1

                if t_idx % 10 == 0:
                    conn.commit()

            conn.commit()
            ds.close()
            total_insert += insert_count
            logger.info(f"   âœ… {nc_file.name}: {insert_count:,}ê°œ")

        except Exception as e:
            logger.warning(f"   âš ï¸  ì˜¤ë¥˜ ({nc_file.name}): {e}")

    # ê²°ê³¼ ì¶œë ¥
    logger.info("=" * 60)
    logger.info("âœ… í•´ìˆ˜ë©´ ìƒìŠ¹ ë°ì´í„° ë¡œë”© ì™„ë£Œ")
    logger.info(f"   - sea_level_grid: {get_row_count(conn, 'sea_level_grid'):,}ê°œ")
    logger.info(f"   - sea_level_data: {get_row_count(conn, 'sea_level_data'):,}ê°œ")
    logger.info("=" * 60)

    cursor.close()
    conn.close()


if __name__ == "__main__":
    load_sea_level()
