"""
SKALA Physical Risk AI System - Load Grid Station Mappings

ë°ì´í„° ì†ŒìŠ¤: grid_to_nearest_stations.json
ëŒ€ìƒ í…Œì´ë¸”: grid_station_mappings (Datawarehouse)
ì˜ˆìƒ ë°ì´í„°: 97,377ê°œ ê²©ì Ã— 3ê°œ ê´€ì¸¡ì†Œ â‰ˆ 292,131ê°œ ë§¤í•‘

Last Modified: 2025-01-24
"""

import sys
import json
from pathlib import Path
from tqdm import tqdm
from utils import setup_logging, get_db_connection, get_data_dir, table_exists


def load_grid_station_mappings() -> None:
    """ê²©ì-ê´€ì¸¡ì†Œ ë§¤í•‘ ë°ì´í„°ë¥¼ JSON íŒŒì¼ì—ì„œ ë¡œë“œí•˜ì—¬ grid_station_mappings í…Œì´ë¸”ì— ì €ì¥"""
    logger = setup_logging("load_grid_station_mappings")
    logger.info("=" * 60)
    logger.info("ê²©ì-ê´€ì¸¡ì†Œ ë§¤í•‘ ë°ì´í„° ë¡œë”© ì‹œì‘")
    logger.info("=" * 60)

    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
    try:
        conn = get_db_connection()
        logger.info("âœ… Datawarehouse ì—°ê²° ì„±ê³µ")
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        sys.exit(1)

    # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not table_exists(conn, "grid_station_mappings"):
        logger.error("âŒ grid_station_mappings í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        logger.error("   ë¨¼ì € 10_create_reference_data_tables.sqlì„ ì‹¤í–‰í•˜ì„¸ìš”")
        conn.close()
        sys.exit(1)

    cursor = conn.cursor()

    # JSON íŒŒì¼ ì°¾ê¸°
    data_dir = get_data_dir()
    json_file = data_dir / "grid_to_nearest_stations.json"

    if not json_file.exists():
        logger.error(f"âŒ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_file}")
        conn.close()
        sys.exit(1)

    logger.info(f"ğŸ“‚ ë°ì´í„° íŒŒì¼: {json_file}")

    try:
        # JSON íŒŒì¼ ì½ê¸°
        with open(json_file, "r", encoding="utf-8") as f:
            data = json.load(f)

        grid_mapping = data.get("grid_mapping", {})
        grid_info = data.get("grid_info", {})

        logger.info(f"ğŸ“Š ê²©ì ì •ë³´:")
        logger.info(f"   - ìœ„ë„ ë²”ìœ„: {grid_info.get('lat_min')}Â°N ~ {grid_info.get('lat_max')}Â°N")
        logger.info(f"   - ê²½ë„ ë²”ìœ„: {grid_info.get('lon_min')}Â°E ~ {grid_info.get('lon_max')}Â°E")
        logger.info(f"   - í•´ìƒë„: {grid_info.get('resolution')}Â°")
        logger.info(f"   - ìœ¡ì§€ ê²©ì: {grid_info.get('n_land_grids'):,}ê°œ")
        logger.info(f"   - ì´ ê²©ì: {len(grid_mapping):,}ê°œ")

        # ê¸°ì¡´ ë°ì´í„° í™•ì¸
        cursor.execute("SELECT COUNT(*) FROM grid_station_mappings")
        existing_count = cursor.fetchone()[0]

        if existing_count > 0:
            logger.warning(f"âš ï¸  ê¸°ì¡´ ë°ì´í„° {existing_count:,}ê°œ ë°œê²¬")
            response = input("ê¸°ì¡´ ë°ì´í„°ë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œ ë¡œë“œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
            if response.lower() != "y":
                logger.info("ì‘ì—…ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤")
                conn.close()
                return

            logger.info("ğŸ—‘ï¸  ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì¤‘...")
            cursor.execute("DELETE FROM grid_station_mappings")
            conn.commit()
            logger.info("âœ… ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")

        # ë°ì´í„° ì‚½ì… SQL
        insert_sql = """
            INSERT INTO grid_station_mappings (
                grid_lat, grid_lon, basin_code, basin_name,
                station_rank, obscd, obsnm,
                station_lat, station_lon, distance_km,
                geom
            ) VALUES (
                %s, %s, %s, %s,
                %s, %s, %s,
                %s, %s, %s,
                ST_SetSRID(ST_MakePoint(%s, %s), 4326)
            )
        """

        # ë°ì´í„° ì‚½ì…
        logger.info("ğŸ’¾ ë°ì´í„° ì‚½ì… ì¤‘...")
        insert_count = 0
        error_count = 0

        # ì§„í–‰ë¥  í‘œì‹œë¥¼ ìœ„í•œ ì „ì²´ ë§¤í•‘ ìˆ˜ ê³„ì‚°
        total_mappings = sum(len(grid_data.get("nearest_stations", [])) for grid_data in grid_mapping.values())
        logger.info(f"ğŸ“Š ì´ {total_mappings:,}ê°œ ë§¤í•‘ ë°œê²¬")

        with tqdm(total=total_mappings, desc="ë§¤í•‘ ë¡œë”©") as pbar:
            for grid_key, grid_data in grid_mapping.items():
                grid_lat = grid_data.get("lat")
                grid_lon = grid_data.get("lon")
                basin_code = grid_data.get("basin_code")
                basin_name = grid_data.get("basin_name")

                nearest_stations = grid_data.get("nearest_stations", [])

                # ê° ê´€ì¸¡ì†Œì— ëŒ€í•´ ìˆœìœ„ë¥¼ ë§¤ê²¨ ì €ì¥
                for rank, station in enumerate(nearest_stations, start=1):
                    try:
                        cursor.execute(insert_sql, (
                            grid_lat,
                            grid_lon,
                            basin_code,
                            basin_name,
                            rank,
                            station.get("obscd"),
                            station.get("obsnm"),
                            station.get("lat"),
                            station.get("lon"),
                            station.get("distance_km"),
                            grid_lon,  # geom - longitude
                            grid_lat,  # geom - latitude
                        ))
                        insert_count += 1
                        pbar.update(1)

                    except Exception as e:
                        error_count += 1
                        logger.error(f"âŒ ë°ì´í„° ì‚½ì… ì‹¤íŒ¨ (grid={grid_key}, rank={rank}): {e}")
                        if error_count > 100:
                            logger.error("âŒ ì˜¤ë¥˜ê°€ ë„ˆë¬´ ë§ì•„ ì‘ì—…ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤")
                            conn.rollback()
                            conn.close()
                            sys.exit(1)
                        pbar.update(1)

                # ì£¼ê¸°ì ìœ¼ë¡œ ì»¤ë°‹ (10,000ê°œë§ˆë‹¤)
                if insert_count % 10000 == 0:
                    conn.commit()

        # ìµœì¢… ì»¤ë°‹
        conn.commit()
        logger.info("âœ… ë°ì´í„° ì‚½ì… ì™„ë£Œ")

        # ìµœì¢… í†µê³„
        cursor.execute("SELECT COUNT(*) FROM grid_station_mappings")
        final_count = cursor.fetchone()[0]

        cursor.execute("""
            SELECT station_rank, COUNT(*)
            FROM grid_station_mappings
            GROUP BY station_rank
            ORDER BY station_rank
        """)
        rank_stats = cursor.fetchall()

        cursor.execute("""
            SELECT basin_name, COUNT(DISTINCT CONCAT(grid_lat::TEXT, ',', grid_lon::TEXT))
            FROM grid_station_mappings
            GROUP BY basin_name
            ORDER BY COUNT(*) DESC
        """)
        basin_stats = cursor.fetchall()

        logger.info("=" * 60)
        logger.info("âœ… ê²©ì-ê´€ì¸¡ì†Œ ë§¤í•‘ ë°ì´í„° ë¡œë”© ì™„ë£Œ")
        logger.info("=" * 60)
        logger.info(f"ğŸ“Š í†µê³„:")
        logger.info(f"   - ì´ ë§¤í•‘: {final_count:,}ê°œ")
        logger.info(f"   - ì‚½ì… ì„±ê³µ: {insert_count:,}ê°œ")
        logger.info(f"   - ì‚½ì… ì‹¤íŒ¨: {error_count:,}ê°œ")
        logger.info("")
        logger.info("ğŸ¯ ìˆœìœ„ë³„ ë§¤í•‘ ìˆ˜:")
        for rank, count in rank_stats:
            logger.info(f"   - Rank {rank}: {count:,}ê°œ")
        logger.info("")
        logger.info("ğŸ“ ìœ ì—­ë³„ ê²©ì ìˆ˜:")
        for basin_name, count in basin_stats[:10]:  # ìƒìœ„ 10ê°œë§Œ í‘œì‹œ
            logger.info(f"   - {basin_name}: {count:,}ê°œ")
        logger.info("=" * 60)

    except Exception as e:
        logger.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        conn.rollback()
        raise
    finally:
        cursor.close()
        conn.close()


if __name__ == "__main__":
    load_grid_station_mappings()
