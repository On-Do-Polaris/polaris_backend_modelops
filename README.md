# SKALA Physical Risk AI - Backend AIops

> ë¬¼ë¦¬ì  ë¦¬ìŠ¤í¬ í™•ë¥  ë° ìœ„í—˜ë„ ìë™ ê³„ì‚° íŒŒì´í”„ë¼ì¸

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-blue.svg)](https://www.postgresql.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

ìµœì¢… ìˆ˜ì •ì¼: 2025-11-25
ë²„ì „: v1.0

---

## ğŸ“‹ ëª©ì°¨

- [ê°œìš”](#ê°œìš”)
- [í”„ë¡œì íŠ¸ êµ¬ì¡°](#í”„ë¡œì íŠ¸-êµ¬ì¡°)
- [ì£¼ìš” ê¸°ëŠ¥](#ì£¼ìš”-ê¸°ëŠ¥)
- [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
- [ë¹ ë¥¸ ì‹œì‘](#ë¹ ë¥¸-ì‹œì‘)
- [ModelOps íŒŒì´í”„ë¼ì¸](#modelops-íŒŒì´í”„ë¼ì¸)
- [ETL íŒŒì´í”„ë¼ì¸](#etl-íŒŒì´í”„ë¼ì¸)
- [í™˜ê²½ ì„¤ì •](#í™˜ê²½-ì„¤ì •)
- [ì‹¤í–‰ ë°©ë²•](#ì‹¤í–‰-ë°©ë²•)
- [ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ](#ë°ì´í„°ë² ì´ìŠ¤-ìŠ¤í‚¤ë§ˆ)
- [ë¬¸ì„œ](#ë¬¸ì„œ)

---

## ê°œìš”

SKALA Physical Risk AI Backend AIopsëŠ” **ê¸°í›„ ë³€í™” ë¬¼ë¦¬ì  ë¦¬ìŠ¤í¬ ë¶„ì„ì„ ìë™í™”**í•˜ëŠ” ë°°ì¹˜ ì²˜ë¦¬ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### í•µì‹¬ ëª©í‘œ

- ğŸ¯ **ìœ„í—˜ ë°œìƒí™•ë¥  P(H) ê³„ì‚°**: binë³„ ë°œìƒí™•ë¥  ë° AAL (ì—°ê°„ í‰ê·  ì†ì‹¤ë¥ ) ìë™ ì‚°ì¶œ
- ğŸ“Š **ìœ„í—˜ë„ H ê³„ì‚°**: 9ê°œ ë¦¬ìŠ¤í¬ë³„ Hazard Score ë° ë“±ê¸‰ ìë™ ì‚°ì¶œ
- ğŸ”„ **ì—°ê°„ ìë™ ì‹¤í–‰**: ë§¤ë…„ 1ì›” 1ì¼ ìë™ ë°°ì¹˜ ì²˜ë¦¬
- ğŸ’¾ **ê²°ê³¼ ì €ì¥**: Application DBì— ê³„ì‚° ê²°ê³¼ ì €ì¥í•˜ì—¬ FastAPI/Spring Boot ì„œë¹„ìŠ¤ ì œê³µ

### ì§€ì› ë¦¬ìŠ¤í¬ ìœ í˜• (9ê°œ)

1. **ê·¹í•œ ê³ ì˜¨** (Extreme Heat)
2. **ê·¹í•œ í•œíŒŒ** (Extreme Cold)
3. **ê°€ë­„** (Drought)
4. **í•˜ì²œ í™ìˆ˜** (River Flood)
5. **ë„ì‹œ í™ìˆ˜** (Urban Flood)
6. **í•´ìˆ˜ë©´ ìƒìŠ¹** (Sea Level Rise)
7. **íƒœí’** (Typhoon)
8. **ì‚°ë¶ˆ** (Wildfire)
9. **ìˆ˜ìì› ìŠ¤íŠ¸ë ˆìŠ¤** (Water Stress)

---

## í”„ë¡œì íŠ¸ êµ¬ì¡°

ì´ ì €ì¥ì†ŒëŠ” **ë‘ ê°œì˜ ë…ë¦½ì ì¸ íŒŒì´í”„ë¼ì¸**ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:

```
backend_aiops/
â”‚
â”œâ”€â”€ ETL/                          # ë°ì´í„° ë¡œë”© íŒŒì´í”„ë¼ì¸ (ì¼íšŒì„±)
â”‚   â”œâ”€â”€ scripts/                  # ê¸°í›„ ë°ì´í„° ë¡œë”© ìŠ¤í¬ë¦½íŠ¸
â”‚   â”‚   â”œâ”€â”€ load_admin_regions.py
â”‚   â”‚   â”œâ”€â”€ load_monthly_grid_data.py
â”‚   â”‚   â”œâ”€â”€ load_yearly_grid_data.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ USAGE.md
â”‚
â”œâ”€â”€ modelops/                     # AI ë°°ì¹˜ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (ì—°ê°„ ìë™)
â”‚   â”œâ”€â”€ agents/                   # ë¦¬ìŠ¤í¬ ê³„ì‚° ì—ì´ì „íŠ¸
â”‚   â”‚   â”œâ”€â”€ probability_calculate/  # P(H) ê³„ì‚° (9ê°œ ì—ì´ì „íŠ¸)
â”‚   â”‚   â”‚   â”œâ”€â”€ base_probability_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ extreme_heat_probability_agent.py
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ hazard_calculate/       # H ê³„ì‚° (9ê°œ ì—ì´ì „íŠ¸)
â”‚   â”‚       â”œâ”€â”€ base_hazard_hscore_agent.py
â”‚   â”‚       â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ batch/                    # ë°°ì¹˜ í”„ë¡œì„¸ì„œ
â”‚   â”‚   â”œâ”€â”€ probability_batch.py      # P(H) ë°°ì¹˜ ì²˜ë¦¬
â”‚   â”‚   â”œâ”€â”€ probability_scheduler.py  # P(H) ìŠ¤ì¼€ì¤„ëŸ¬
â”‚   â”‚   â”œâ”€â”€ hazard_batch.py          # H ë°°ì¹˜ ì²˜ë¦¬
â”‚   â”‚   â””â”€â”€ hazard_scheduler.py      # H ìŠ¤ì¼€ì¤„ëŸ¬
â”‚   â”‚
â”‚   â”œâ”€â”€ database/                 # DB ì—°ê²°
â”‚   â”‚   â””â”€â”€ connection.py
â”‚   â”‚
â”‚   â”œâ”€â”€ config/                   # ì„¤ì •
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â”‚
â”‚   â””â”€â”€ triggers/                 # DB NOTIFY ë¦¬ìŠ¤ë„ˆ
â”‚       â””â”€â”€ notify_listener.py
â”‚
â”œâ”€â”€ Physical_RISK_calculate/      # ë¬¼ë¦¬ì  ë¦¬ìŠ¤í¬ ê³„ì‚° ë¡œì§ (ì°¸ê³ ìš©)
â”‚
â”œâ”€â”€ docs/                         # ë¬¸ì„œ
â”‚   â”œâ”€â”€ ERD_Diagram.md
â”‚   â”œâ”€â”€ DEPLOYMENT_GUIDE.md
â”‚   â”œâ”€â”€ GITHUB_SECRETS.md
â”‚   â””â”€â”€ LOCAL_CICD_TEST.md
â”‚
â”œâ”€â”€ main.py                       # ModelOps ì§„ì…ì 
â”œâ”€â”€ pyproject.toml                # ModelOps ì˜ì¡´ì„±
â”œâ”€â”€ Dockerfile                    # ë°°í¬ìš© ì»¨í…Œì´ë„ˆ
â””â”€â”€ README.md                     # ë³¸ ë¬¸ì„œ
```

---

## ì£¼ìš” ê¸°ëŠ¥

### 1. **ìœ„í—˜ ë°œìƒí™•ë¥  P(H) ìë™ ê³„ì‚°**

#### ê³„ì‚° ë°©ì‹
- **ê°•ë„ì§€í‘œ X(t)**: ì—°ë„ë³„/ì›”ë³„ ë¦¬ìŠ¤í¬ ê°•ë„ ê³„ì‚°
- **bin ë¶„ë¥˜**: ê°•ë„ì— ë”°ë¥¸ êµ¬ê°„ ë¶„ë¥˜
- **ë°œìƒí™•ë¥  P[i]**: KDE ê¸°ë°˜ ì—°ì†ì  í™•ë¥  ë¶„í¬ ì¶”ì •
- **AAL ê³„ì‚°**: `AAL = Î£(P[i] Ã— DR[i])`

#### ê²°ê³¼ ì €ì¥
```sql
probability_results (
    latitude, longitude, risk_type,
    probability,  -- AAL (ì—°ê°„ í‰ê·  ì†ì‹¤ë¥ )
    bin_data      -- binë³„ í™•ë¥ /ì†ìƒë¥  (JSONB)
)
```

#### bin_data êµ¬ì¡°
```json
[
  {"bin": 1, "range": "0~3", "probability": 0.8000, "base_damage_rate": 0.0010},
  {"bin": 2, "range": "3~8", "probability": 0.1200, "base_damage_rate": 0.0030},
  ...
]
```

### 2. **ìœ„í—˜ë„ H ìë™ ê³„ì‚°**

#### ê³„ì‚° ë°©ì‹
- **ê¸°í›„ ë°ì´í„° ì¡°íšŒ**: Datawarehouseì—ì„œ ê²©ìë³„ ê¸°í›„ ì‹œê³„ì—´ ì¡°íšŒ
- **Hazard Score ì‚°ì¶œ**: ë¦¬ìŠ¤í¬ë³„ íŠ¹í™”ëœ ì•Œê³ ë¦¬ì¦˜ ì ìš©
- **ë“±ê¸‰ ë¶„ë¥˜**: MINIMAL, LOW, MEDIUM, HIGH, CRITICAL

#### ê²°ê³¼ ì €ì¥
```sql
hazard_results (
    latitude, longitude, risk_type,
    hazard_score,       -- ì›ë³¸ ì ìˆ˜
    hazard_score_100,   -- 0-100 ì •ê·œí™” ì ìˆ˜
    hazard_level        -- ë“±ê¸‰
)
```

### 3. **ìë™ ìŠ¤ì¼€ì¤„ë§**

#### ìŠ¤ì¼€ì¤„ ì„¤ì •
```python
# settings.py
probability_schedule: ë§¤ë…„ 1ì›” 1ì¼ 02:00
hazard_schedule: ë§¤ë…„ 1ì›” 1ì¼ 04:00
```

#### ì‹¤í–‰ íë¦„
```
ë§¤ë…„ 1ì›” 1ì¼ 02:00
  â†“
[ProbabilityScheduler ì‹¤í–‰]
  â†“
ì „ì²´ ê²©ì (451,351ê°œ) ì¡°íšŒ
  â†“
9ê°œ ë¦¬ìŠ¤í¬ Ã— ì „ì²´ ê²©ì ë³‘ë ¬ ê³„ì‚°
  â†“
AAL + bin_data â†’ probability_results í…Œì´ë¸”
  â†“
2ì‹œê°„ í›„ (04:00)
  â†“
[HazardScheduler ì‹¤í–‰]
  â†“
Hazard Score ê³„ì‚° ë° ì €ì¥
  â†“
ì™„ë£Œ (ì•½ 5ì‹œê°„ ì†Œìš”)
```

### 4. **DB NOTIFY íŠ¸ë¦¬ê±° ì§€ì›**

ìˆ˜ë™ ì‹¤í–‰ í•„ìš” ì‹œ:

```sql
-- PostgreSQLì—ì„œ íŠ¸ë¦¬ê±°
NOTIFY probability;  -- P(H) ë°°ì¹˜ ì¦‰ì‹œ ì‹¤í–‰
NOTIFY hazard;       -- H ë°°ì¹˜ ì¦‰ì‹œ ì‹¤í–‰
```

### 5. **ë³‘ë ¬ ì²˜ë¦¬**

```python
# settings.py
parallel_workers: 4  # ë™ì‹œ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜
```

- ProcessPoolExecutor ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬
- ê²©ìë³„ ë…ë¦½ ê³„ì‚°ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”

---

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SKALA Physical Risk AI                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Application DB      â”‚       Datawarehouse          â”‚
â”‚  (PostgreSQL 16)     â”‚       (PostGIS 16-3.4)       â”‚
â”‚  í¬íŠ¸: 5432          â”‚       í¬íŠ¸: 5433              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                      â”‚                              â”‚
â”‚ â€¢ users              â”‚ â€¢ location_admin (5,259)     â”‚
â”‚ â€¢ sites              â”‚ â€¢ location_grid (451,351)    â”‚
â”‚ â€¢ analysis_jobs      â”‚ â€¢ ta_data (433M rows)        â”‚
â”‚ â€¢ physical_risk_     â”‚ â€¢ rn_data (433M rows)        â”‚
â”‚   scores             â”‚ â€¢ wsdi_data (36M rows)       â”‚
â”‚                      â”‚ â€¢ csdi_data (36M rows)       â”‚
â”‚ â€¢ probability_       â”‚ â€¢ ... (14ê°œ ê¸°í›„ í…Œì´ë¸”)      â”‚
â”‚   results âœ¨         â”‚                              â”‚
â”‚ â€¢ hazard_results âœ¨  â”‚ â€¢ raw_dem (ë˜ìŠ¤í„°)           â”‚
â”‚                      â”‚ â€¢ raw_landcover (ë˜ìŠ¤í„°)     â”‚
â”‚                      â”‚ â€¢ API ìºì‹œ (11ê°œ í…Œì´ë¸”)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### íŒŒì´í”„ë¼ì¸ íë¦„

```mermaid
graph LR
    A[ì™¸ë¶€ ê¸°í›„ ë°ì´í„°<br/>NetCDF/GeoTIFF] -->|ETL Pipeline| B[Datawarehouse<br/>Port 5433]
    B -->|fetch_climate_data| C[ModelOps<br/>Agents]
    C -->|P_H ê³„ì‚°| D[probability_results]
    C -->|H ê³„ì‚°| E[hazard_results]
    D --> F[Application DB<br/>Port 5432]
    E --> F
    F -->|ì¡°íšŒ| G[FastAPI/Spring Boot<br/>ì„œë¹„ìŠ¤]
```

---

## ë¹ ë¥¸ ì‹œì‘

### ì‚¬ì „ ìš”êµ¬ì‚¬í•­

- Python 3.11+
- PostgreSQL 16 (Application DB - í¬íŠ¸ 5432)
- PostgreSQL 16 + PostGIS 3.4 (Datawarehouse - í¬íŠ¸ 5433)
- 8GB+ RAM
- 100GB+ ë””ìŠ¤í¬ ê³µê°„

### ì„¤ì¹˜

```bash
# 1. ì €ì¥ì†Œ í´ë¡ 
git clone <repository-url>
cd backend_aiops

# 2. ê°€ìƒí™˜ê²½ ìƒì„± ë° ì˜ì¡´ì„± ì„¤ì¹˜
uv sync

# ë˜ëŠ” pip ì‚¬ìš©
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -e .
```

### í™˜ê²½ ì„¤ì •

```bash
# .env íŒŒì¼ ìƒì„±
cat > .env << EOF
# Application Database
DATABASE_HOST=localhost
DATABASE_PORT=5432
DATABASE_NAME=skala_application
DATABASE_USER=skala_app_user
DATABASE_PASSWORD=your_password

# Datawarehouse
DW_HOST=localhost
DW_PORT=5433
DW_NAME=skala_datawarehouse
DW_USER=skala_dw_user
DW_PASSWORD=your_password

# Scheduler Settings
PROBABILITY_SCHEDULE_MONTH=1
PROBABILITY_SCHEDULE_DAY=1
PROBABILITY_SCHEDULE_HOUR=2
PROBABILITY_SCHEDULE_MINUTE=0

HAZARD_SCHEDULE_MONTH=1
HAZARD_SCHEDULE_DAY=1
HAZARD_SCHEDULE_HOUR=4
HAZARD_SCHEDULE_MINUTE=0

# Performance
PARALLEL_WORKERS=4
EOF
```

### ì‹¤í–‰ ìˆœì„œ

#### 1ë‹¨ê³„: ETL ì‹¤í–‰ (ìµœì´ˆ 1íšŒ í•„ìˆ˜!)

```bash
cd ETL

# ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ (2-3ë¶„)
export SAMPLE_LIMIT=10
./test_sample_load.sh

# ì „ì²´ ë°ì´í„° ë¡œë“œ (12-15ì‹œê°„)
unset SAMPLE_LIMIT
python scripts/load_admin_regions.py
python scripts/load_monthly_grid_data.py
python scripts/load_yearly_grid_data.py
python scripts/load_sea_level_netcdf.py
```

#### 2ë‹¨ê³„: ModelOps ì‹¤í–‰

```bash
cd ..

# ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰)
python main.py
```

ì¶œë ¥ ì˜ˆì‹œ:
```
Starting AIops workflow system
Schedulers started
  - Probability: 1/1 02:00
  - Hazard: 1/1 04:00
Listening for NOTIFY events...
```

---

## ModelOps íŒŒì´í”„ë¼ì¸

### 1. **Probability ê³„ì‚° íŒŒì´í”„ë¼ì¸**

#### ì‹¤í–‰ ìŠ¤ì¼€ì¤„
- **ìë™**: ë§¤ë…„ 1ì›” 1ì¼ 02:00
- **ìˆ˜ë™**: `NOTIFY probability;`

#### ì²˜ë¦¬ íë¦„

```python
# probability_batch.py
ì „ì²´ ê²©ì ì¡°íšŒ (451,351ê°œ)
  â†“
ê²©ìë³„ ë³‘ë ¬ ì²˜ë¦¬ (4 workers)
  â†“
ê° ê²©ìë‹¹:
  1. ê¸°í›„ ë°ì´í„° ì¡°íšŒ (Datawarehouse)
  2. 9ê°œ ë¦¬ìŠ¤í¬ ì—ì´ì „íŠ¸ ì‹¤í–‰
     - ê°•ë„ì§€í‘œ X(t) ê³„ì‚°
     - bin ë¶„ë¥˜ ë° ë°œìƒí™•ë¥  P[i] ê³„ì‚°
     - AAL = Î£(P[i] Ã— DR[i])
  3. ê²°ê³¼ ì €ì¥ (Application DB)
  â†“
ì™„ë£Œ (ì•½ 2-3ì‹œê°„)
```

#### ì—ì´ì „íŠ¸ ëª©ë¡

| ì—ì´ì „íŠ¸ | ê°•ë„ì§€í‘œ | bin ê¸°ì¤€ | ì‹œê°„ ë‹¨ìœ„ |
|---------|---------|---------|----------|
| `ExtremeHeatProbabilityAgent` | WSDI | ë¶„ìœ„ìˆ˜ ê¸°ë°˜ (Q80, Q90, Q95, Q99) | Yearly |
| `ExtremeColdProbabilityAgent` | CSDI | ë¶„ìœ„ìˆ˜ ê¸°ë°˜ | Yearly |
| `DroughtProbabilityAgent` | SPEI-12 | ê°€ë­„ ë“±ê¸‰ (-2, -1.5, -1, -0.5) | Monthly |
| `RiverFloodProbabilityAgent` | RX5DAY | ê°•ìˆ˜ëŸ‰ ê¸°ì¤€ (100, 150, 200, 300mm) | Yearly |
| `UrbanFloodProbabilityAgent` | RX1DAY | ê°•ìˆ˜ëŸ‰ ê¸°ì¤€ (50, 80, 120, 200mm) | Yearly |
| `SeaLevelRiseProbabilityAgent` | í•´ìˆ˜ë©´ ìƒìŠ¹(cm) | ìƒìŠ¹ ë†’ì´ (20, 40, 60, 100cm) | Yearly |
| `TyphoonProbabilityAgent` | í’ì†(m/s) | ë“±ê¸‰ ê¸°ì¤€ (17, 25, 33, 44 m/s) | Event-based |
| `WildfireProbabilityAgent` | FWI | ìœ„í—˜ë„ (low, moderate, high, extreme) | Monthly |
| `WaterStressProbabilityAgent` | ìˆ˜ìì› ë¹„ìœ¨ | ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€ (0.8, 0.6, 0.4, 0.2) | Yearly |

#### ê²°ê³¼ ë°ì´í„°

```json
{
  "risk_type": "extreme_heat",
  "aal": 0.0025,
  "bin_data": [
    {"bin": 1, "range": "0~3", "probability": 0.8000, "base_damage_rate": 0.0010},
    {"bin": 2, "range": "3~8", "probability": 0.1200, "base_damage_rate": 0.0030},
    {"bin": 3, "range": "8~20", "probability": 0.0500, "base_damage_rate": 0.0100},
    {"bin": 4, "range": "20~40", "probability": 0.0250, "base_damage_rate": 0.0200},
    {"bin": 5, "range": "40~inf", "probability": 0.0050, "base_damage_rate": 0.0350}
  ]
}
```

### 2. **Hazard Score ê³„ì‚° íŒŒì´í”„ë¼ì¸**

#### ì‹¤í–‰ ìŠ¤ì¼€ì¤„
- **ìë™**: ë§¤ë…„ 1ì›” 1ì¼ 04:00 (Probability 2ì‹œê°„ í›„)
- **ìˆ˜ë™**: `NOTIFY hazard;`

#### ì²˜ë¦¬ íë¦„

```python
# hazard_batch.py
ì „ì²´ ê²©ì ì¡°íšŒ (451,351ê°œ)
  â†“
ê²©ìë³„ ë³‘ë ¬ ì²˜ë¦¬ (4 workers)
  â†“
ê° ê²©ìë‹¹:
  1. ê¸°í›„ ë°ì´í„° ì¡°íšŒ (Datawarehouse)
  2. 9ê°œ ë¦¬ìŠ¤í¬ ì—ì´ì „íŠ¸ ì‹¤í–‰
     - ë¦¬ìŠ¤í¬ë³„ íŠ¹í™” ì ìˆ˜ ê³„ì‚°
     - 0-100 ì •ê·œí™”
     - ë“±ê¸‰ ë¶„ë¥˜ (MINIMAL~CRITICAL)
  3. ê²°ê³¼ ì €ì¥ (Application DB)
  â†“
ì™„ë£Œ (ì•½ 2-3ì‹œê°„)
```

#### ê²°ê³¼ ë°ì´í„°

```json
{
  "risk_type": "extreme_heat",
  "hazard_score": 75.5,
  "hazard_score_100": 75.5,
  "hazard_level": "HIGH"
}
```

---

## ETL íŒŒì´í”„ë¼ì¸

### ì—­í• 

**Datawarehouseì— ê¸°í›„ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ì¼íšŒì„± ì‘ì—…**

- ì™¸ë¶€ NetCDF, Shapefile, GeoTIFF â†’ PostgreSQL
- ModelOpsì˜ **ì „ì œì¡°ê±´** (ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì‘ë™ ë¶ˆê°€)

### ì£¼ìš” ìŠ¤í¬ë¦½íŠ¸

| ìŠ¤í¬ë¦½íŠ¸ | ì…ë ¥ | ì¶œë ¥ í…Œì´ë¸” | ì‹œê°„ | í–‰ ìˆ˜ |
|---------|------|-----------|------|------|
| `load_admin_regions.py` | Shapefile | `location_admin` | 2ë¶„ | 5,259 |
| `load_monthly_grid_data.py` | NetCDF | `ta_data`, `rn_data` ë“± | 3ì‹œê°„ | 433M/í…Œì´ë¸” |
| `load_yearly_grid_data.py` | NetCDF | `wsdi_data`, `csdi_data` ë“± | 2ì‹œê°„ | 36M/í…Œì´ë¸” |
| `load_sea_level_netcdf.py` | NetCDF | `sea_level_data` | 5ë¶„ | 6,880 |
| `load_landcover.py` | GeoTIFF | `raw_landcover` (ë˜ìŠ¤í„°) | 3ì‹œê°„ | ~500 GB |

### ì‹¤í–‰

```bash
cd ETL
uv sync
python scripts/load_admin_regions.py
python scripts/load_monthly_grid_data.py
# ... (ìì„¸í•œ ë‚´ìš©ì€ ETL/README.md ì°¸ì¡°)
```

**ìƒì„¸ ë¬¸ì„œ**: [ETL/README.md](ETL/README.md), [ETL/USAGE.md](ETL/USAGE.md)

---

## í™˜ê²½ ì„¤ì •

### í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜

**ì¤‘ìš”**: ì´ í”„ë¡œì íŠ¸ëŠ” **`.env` íŒŒì¼ì—ì„œë§Œ** í™˜ê²½ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

`.env` íŒŒì¼ ìƒì„±:

```bash
# Data Warehouse Configuration (Primary DB for climate data)
DW_HOST=localhost
DW_PORT=5433
DW_NAME=skala_datawarehouse
DW_USER=skala_dw_user
DW_PASSWORD=1234

# Application Database Configuration (For Spring Boot - user/site data)
APP_HOST=localhost
APP_PORT=5432
APP_NAME=skala_application
APP_USER=skala_app_user
APP_PASSWORD=your_password

# Database Configuration (Legacy - for backward compatibility)
DATABASE_HOST=localhost
DATABASE_PORT=5433
DATABASE_NAME=skala_datawarehouse
DATABASE_USER=skala_dw_user
DATABASE_PASSWORD=1234

# Scheduler Configuration
PROBABILITY_SCHEDULE_MONTH=1
PROBABILITY_SCHEDULE_DAY=1
PROBABILITY_SCHEDULE_HOUR=2
PROBABILITY_SCHEDULE_MINUTE=0

HAZARD_SCHEDULE_MONTH=1
HAZARD_SCHEDULE_DAY=1
HAZARD_SCHEDULE_HOUR=4
HAZARD_SCHEDULE_MINUTE=0

# Batch Processing Configuration
PARALLEL_WORKERS=4
BATCH_SIZE=1000

# PostgreSQL LISTEN/NOTIFY
NOTIFY_CHANNEL=aiops_trigger
```

### ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜ ì œê±° (ì„ íƒì‚¬í•­)

ì‹œìŠ¤í…œì— DB ê´€ë ¨ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆë‹¤ë©´, í˜¼ë€ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì œê±°í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤:

```powershell
# PowerShell ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
.\clear_system_env_vars.ps1
```

ë˜ëŠ” ìˆ˜ë™ìœ¼ë¡œ ì œê±°:
- Windows: ì‹œìŠ¤í…œ ì†ì„± â†’ í™˜ê²½ë³€ìˆ˜ â†’ ì‚¬ìš©ì/ì‹œìŠ¤í…œ ë³€ìˆ˜ì—ì„œ `DW_*`, `APP_*`, `DATABASE_*` ì œê±°
- Linux/Mac: `~/.bashrc` ë˜ëŠ” `~/.zshrc`ì—ì„œ ê´€ë ¨ export êµ¬ë¬¸ ì œê±°

---

## ì‹¤í–‰ ë°©ë²•

### 1. **ìë™ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ (í”„ë¡œë•ì…˜)**

```bash
# ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
nohup python main.py > logs/modelops.log 2>&1 &

# ë˜ëŠ” systemd ì„œë¹„ìŠ¤ë¡œ ì‹¤í–‰ (Linux)
sudo systemctl start aiops-modelops
```

### 2. **ìˆ˜ë™ ë°°ì¹˜ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸)**

#### Probability ë°°ì¹˜ë§Œ ì‹¤í–‰

```python
from modelops.batch.probability_batch import ProbabilityBatchProcessor
from modelops.database.connection import DatabaseConnection

processor = ProbabilityBatchProcessor({'parallel_workers': 4})
grid_coordinates = DatabaseConnection.fetch_grid_coordinates()
result = processor.process_all_grids(grid_coordinates)
print(result)
```

#### Hazard ë°°ì¹˜ë§Œ ì‹¤í–‰

```python
from modelops.batch.hazard_batch import HazardBatchProcessor
from modelops.database.connection import DatabaseConnection

processor = HazardBatchProcessor({'parallel_workers': 4})
grid_coordinates = DatabaseConnection.fetch_grid_coordinates()
result = processor.process_all_grids(grid_coordinates)
print(result)
```

### 3. **DB NOTIFY íŠ¸ë¦¬ê±°**

```bash
# PostgreSQLì— ì ‘ì†
psql -h localhost -p 5432 -U skala_app_user -d skala_application

# NOTIFY ì´ë²¤íŠ¸ ë°œìƒ
NOTIFY probability;  -- P(H) ë°°ì¹˜ ì¦‰ì‹œ ì‹¤í–‰
NOTIFY hazard;       -- H ë°°ì¹˜ ì¦‰ì‹œ ì‹¤í–‰
```

### 4. **Docker ì‹¤í–‰**

```bash
# Docker ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t skala-aiops-modelops .

# ì‹¤í–‰
docker run -d \
  --name aiops-modelops \
  --env-file .env \
  skala-aiops-modelops
```

---

## ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

### Application DB í…Œì´ë¸”

#### probability_results

| ì»¬ëŸ¼ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| `latitude` | NUMERIC | ìœ„ë„ (PK) |
| `longitude` | NUMERIC | ê²½ë„ (PK) |
| `risk_type` | VARCHAR | ë¦¬ìŠ¤í¬ íƒ€ì… (PK) |
| `probability` | REAL | **AAL** = Î£(P[i] Ã— DR[i]) |
| `bin_data` | JSONB | binë³„ í™•ë¥ /ì†ìƒë¥  ë°°ì—´ |
| `calculated_at` | TIMESTAMPTZ | ê³„ì‚° ì‹œê° |

**probability ì»¬ëŸ¼**: AAL (Annual Average Loss, ì—°ê°„ í‰ê·  ì†ì‹¤ë¥ )
- ê³µì‹: `AAL = Î£(P[i] Ã— DR[i])`
- ë²”ìœ„: 0.0 ~ 1.0 (0% ~ 100%)
- ì˜ˆì‹œ: 0.0025 = 0.25%

#### hazard_results

| ì»¬ëŸ¼ | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| `latitude` | NUMERIC | ìœ„ë„ (PK) |
| `longitude` | NUMERIC | ê²½ë„ (PK) |
| `risk_type` | VARCHAR | ë¦¬ìŠ¤í¬ íƒ€ì… (PK) |
| `hazard_score` | REAL | ì›ë³¸ ìœ„í—˜ë„ ì ìˆ˜ |
| `hazard_score_100` | REAL | 0-100 ì •ê·œí™” ì ìˆ˜ |
| `hazard_level` | VARCHAR | ìœ„í—˜ ë“±ê¸‰ |
| `calculated_at` | TIMESTAMPTZ | ê³„ì‚° ì‹œê° |

**hazard_level ë“±ê¸‰**:
- `MINIMAL`: < 20
- `LOW`: 20-40
- `MEDIUM`: 40-60
- `HIGH`: 60-80
- `CRITICAL`: 80+

**ìƒì„¸ ERD**: [docs/ERD_Diagram.md](docs/ERD_Diagram.md)

---

## ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### ë¡œê·¸ í™•ì¸

```bash
# ì‹¤ì‹œê°„ ë¡œê·¸ ëª¨ë‹ˆí„°ë§
tail -f logs/modelops.log

# ì—ëŸ¬ ê²€ìƒ‰
grep -i "error\|failed" logs/modelops.log

# ì™„ë£Œ í™•ì¸
grep -i "completed" logs/modelops.log
```

### ë°°ì¹˜ ì§„í–‰ ìƒí™© í™•ì¸

```sql
-- ê³„ì‚°ëœ ê²©ì ìˆ˜ í™•ì¸
SELECT
    risk_type,
    COUNT(*) AS calculated_grids,
    MAX(calculated_at) AS last_update
FROM probability_results
GROUP BY risk_type
ORDER BY risk_type;

-- Hazard Score ì™„ë£Œ ìƒí™©
SELECT
    risk_type,
    COUNT(*) AS calculated_grids,
    AVG(hazard_score_100) AS avg_score,
    MAX(calculated_at) AS last_update
FROM hazard_results
GROUP BY risk_type
ORDER BY risk_type;
```

### ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```bash
# ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤
htop

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
docker exec skala_application psql -U skala_app_user -d skala_application -c "
SELECT count(*) FROM pg_stat_activity WHERE state = 'active'
"

# ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸°
docker exec skala_application psql -U skala_app_user -d skala_application -c "
SELECT pg_size_pretty(pg_database_size('skala_application'))
"
```

---

## ì„±ëŠ¥ ìµœì í™”

### ë³‘ë ¬ ì›Œì»¤ ìˆ˜ ì¡°ì •

```bash
# .env íŒŒì¼ì—ì„œ
PARALLEL_WORKERS=8  # CPU ì½”ì–´ ìˆ˜ì— ë§ì¶° ì¡°ì •
```

### ë°ì´í„°ë² ì´ìŠ¤ íŠœë‹

```sql
-- work_mem ì¦ê°€
ALTER SYSTEM SET work_mem = '256MB';

-- maintenance_work_mem ì¦ê°€
ALTER SYSTEM SET maintenance_work_mem = '1GB';

-- ì¬ì‹œì‘
SELECT pg_reload_conf();
```

### ë°°ì¹˜ í¬ê¸° ì¡°ì •

```python
# probability_batch.py ë˜ëŠ” hazard_batch.py
# ProcessPoolExecutorì˜ max_workers ì¡°ì •
```

---

## ë¬¸ì œ í•´ê²°

### ë¬¸ì œ 1: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨

```bash
# ì¦ìƒ
psycopg2.OperationalError: could not connect to server

# í•´ê²°
# 1. ë°ì´í„°ë² ì´ìŠ¤ ì‹¤í–‰ í™•ì¸
docker ps | grep skala

# 2. ì—°ê²° í…ŒìŠ¤íŠ¸
psql -h localhost -p 5432 -U skala_app_user -d skala_application
psql -h localhost -p 5433 -U skala_dw_user -d skala_datawarehouse

# 3. .env íŒŒì¼ í™•ì¸
cat .env
```

### ë¬¸ì œ 2: ETL ë°ì´í„° ì—†ìŒ

```bash
# ì¦ìƒ
ERROR: fetch_climate_data returned empty result

# í•´ê²°
# Datawarehouseì— ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
docker exec skala_datawarehouse psql -U skala_dw_user -d skala_datawarehouse -c "
SELECT COUNT(*) FROM wsdi_data;
"

# ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ETL ë¨¼ì € ì‹¤í–‰
cd ETL
python scripts/load_yearly_grid_data.py
```

### ë¬¸ì œ 3: ë©”ëª¨ë¦¬ ë¶€ì¡±

```bash
# ì¦ìƒ
MemoryError: Unable to allocate array

# í•´ê²°
# 1. ë³‘ë ¬ ì›Œì»¤ ìˆ˜ ì¤„ì´ê¸°
PARALLEL_WORKERS=2

# 2. Docker ë©”ëª¨ë¦¬ ì¦ê°€
# Docker Desktop â†’ Settings â†’ Resources â†’ Memory: 8GB+
```

### ë¬¸ì œ 4: ìŠ¤ì¼€ì¤„ëŸ¬ ì‘ë™ ì•ˆ í•¨

```python
# ë¡œê·¸ í™•ì¸
tail -f logs/modelops.log

# ìŠ¤ì¼€ì¤„ í™•ì¸
# main.py ì‹¤í–‰ ì‹œ ì¶œë ¥ë˜ëŠ” ìŠ¤ì¼€ì¤„ ì‹œê°„ í™•ì¸
# Schedulers started
#   - Probability: 1/1 02:00
#   - Hazard: 1/1 04:00

# ìˆ˜ë™ íŠ¸ë¦¬ê±°ë¡œ í…ŒìŠ¤íŠ¸
# psqlì—ì„œ: NOTIFY probability;
```

---

## ë°°í¬

### Docker ë°°í¬

```bash
# ì´ë¯¸ì§€ ë¹Œë“œ
docker build -t skala-aiops-modelops:latest .

# ì‹¤í–‰
docker run -d \
  --name aiops-modelops \
  --env-file .env \
  --restart unless-stopped \
  skala-aiops-modelops:latest

# ë¡œê·¸ í™•ì¸
docker logs -f aiops-modelops
```

### Kubernetes ë°°í¬

```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: aiops-modelops
spec:
  replicas: 1
  selector:
    matchLabels:
      app: aiops-modelops
  template:
    metadata:
      labels:
        app: aiops-modelops
    spec:
      containers:
      - name: modelops
        image: skala-aiops-modelops:latest
        envFrom:
        - secretRef:
            name: aiops-secrets
        resources:
          requests:
            memory: "4Gi"
            cpu: "2"
          limits:
            memory: "8Gi"
            cpu: "4"
```

**ìƒì„¸ ë°°í¬ ê°€ì´ë“œ**: [docs/DEPLOYMENT_GUIDE.md](docs/DEPLOYMENT_GUIDE.md)

---

## ê°œë°œ

### ë¡œì»¬ ê°œë°œ í™˜ê²½

```bash
# ê°œë°œ ì˜ì¡´ì„± ì„¤ì¹˜
uv sync --dev

# ë˜ëŠ”
pip install -e ".[dev]"

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest

# ì½”ë“œ í¬ë§·íŒ…
black .

# Linting
ruff check .

# íƒ€ì… ì²´í‚¹
mypy modelops
```

### í…ŒìŠ¤íŠ¸

```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸
pytest

# ì»¤ë²„ë¦¬ì§€ í¬í•¨
pytest --cov=modelops --cov-report=html

# íŠ¹ì • ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸
pytest scratch/test_future_probability_agents.py
```

---

## ë¬¸ì„œ

### ì£¼ìš” ë¬¸ì„œ

- [ERD ë‹¤ì´ì–´ê·¸ë¨](docs/ERD_Diagram.md) - ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ
- [ë°°í¬ ê°€ì´ë“œ](docs/DEPLOYMENT_GUIDE.md) - Docker/Kubernetes ë°°í¬
- [GitHub Secrets](docs/GITHUB_SECRETS.md) - CI/CD ì„¤ì •
- [ë¡œì»¬ CI/CD í…ŒìŠ¤íŠ¸](docs/LOCAL_CICD_TEST.md) - GitHub Actions ë¡œì»¬ í…ŒìŠ¤íŠ¸

### ETL ë¬¸ì„œ

- [ETL README](ETL/README.md) - ETL ê°œìš”
- [ETL USAGE](ETL/USAGE.md) - ETL ì‚¬ìš© ê°€ì´ë“œ
- [ETL SETUP](ETL/SETUP.md) - ETL ì„¤ì¹˜ ê°€ì´ë“œ

---

## API ì—”ë“œí¬ì¸íŠ¸ (ì°¸ê³ ìš©)

ModelOps ë°°ì¹˜ ê²°ê³¼ëŠ” FastAPI/Spring Boot ì„œë¹„ìŠ¤ì—ì„œ ì¡°íšŒ ê°€ëŠ¥:

```bash
# Probability ê²°ê³¼ ì¡°íšŒ
GET /api/v1/probability?lat=37.5&lon=127.0&risk_type=extreme_heat

# Hazard Score ì¡°íšŒ
GET /api/v1/hazard?lat=37.5&lon=127.0&risk_type=extreme_heat
```

**ì‘ë‹µ ì˜ˆì‹œ**:

```json
{
  "latitude": 37.5,
  "longitude": 127.0,
  "risk_type": "extreme_heat",
  "aal": 0.0025,
  "bin_data": [
    {"bin": 1, "range": "0~3", "probability": 0.8, "base_damage_rate": 0.001},
    ...
  ],
  "calculated_at": "2025-01-01T06:30:00Z"
}
```

---

## ê¸°ì—¬

### ì»¤ë°‹ ì»¨ë²¤ì…˜

```bash
# ê¸°ëŠ¥ ì¶”ê°€
feat: Add new probability agent for landslide risk

# ë²„ê·¸ ìˆ˜ì •
fix: Correct AAL calculation in base agent

# ë¬¸ì„œ
docs: Update README with deployment instructions

# ë¦¬íŒ©í† ë§
refactor: Simplify bin classification logic
```

### ë¸Œëœì¹˜ ì „ëµ

```bash
main              # í”„ë¡œë•ì…˜
develop           # ê°œë°œ
feature/*         # ê¸°ëŠ¥ ê°œë°œ
hotfix/*          # ê¸´ê¸‰ ìˆ˜ì •
```

---

## ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

---

## ì§€ì›

ì§ˆë¬¸ì´ë‚˜ ë¬¸ì œê°€ ìˆëŠ” ê²½ìš°:
- ì´ìŠˆ ë“±ë¡: [GitHub Issues](https://github.com/On-Do-Polaris/backend_aiops/issues)
- SKALA Physical Risk AI íŒ€ ë¬¸ì˜

---

## íŒ€

**SKALA Physical Risk AI Team**

- ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§: ETL íŒŒì´í”„ë¼ì¸ ê°œë°œ
- ML ì—”ì§€ë‹ˆì–´ë§: ModelOps ì—ì´ì „íŠ¸ ê°œë°œ
- DevOps: ë°°í¬ ë° ì¸í”„ë¼ ê´€ë¦¬

---

**ìµœì¢… ìˆ˜ì •**: 2025-11-25
**ë²„ì „**: v1.0
**ë¬¸ì„œ ì‘ì„±**: SKALA Physical Risk AI Team
