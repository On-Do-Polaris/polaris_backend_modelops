"""
==================================================================
[ëª¨ë“ˆëª…] agents/supervisor.py
ìˆ˜í¼ë°”ì´ì € ì—ì´ì „íŠ¸

[ëª¨ë“ˆ ëª©í‘œ]
1) ìˆ˜ì§‘ ë°ì´í„° í†µí•© ë° ê²€ì¦
2) ESG ì¸ì‚¬ì´íŠ¸ ë¶„ì„ (LLM í™œìš©)
==================================================================
"""
from typing import Dict, List
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from ..state import ESGTrendsState
from ..utils.config import Config
from ..utils.logging import get_logger
from ..prompts import SUPERVISOR_SYSTEM_PROMPT, SUPERVISOR_ANALYSIS_PROMPT

logger = get_logger("esg_agent.supervisor")

# ESG ê´€ë ¨ í‚¤ì›Œë“œ (í•„í„°ë§ìš©)
ESG_KEYWORDS = [
    # E (í™˜ê²½)
    "í™˜ê²½", "íƒ„ì†Œ", "ê¸°í›„", "ì¹œí™˜ê²½", "ì¬ìƒì—ë„ˆì§€", "íƒœì–‘ê´‘", "í’ë ¥", "ì „ê¸°ì°¨", "EV",
    "íƒˆíƒ„ì†Œ", "ë„·ì œë¡œ", "ì˜¨ì‹¤ê°€ìŠ¤", "ë°°ì¶œ", "CBAM", "íƒ„ì†Œêµ­ê²½", "RE100", "ê·¸ë¦°",
    "íê¸°ë¬¼", "ì¬í™œìš©", "í”Œë¼ìŠ¤í‹±", "ìƒë¬¼ë‹¤ì–‘ì„±", "ìˆ˜ìì›", "ì˜¤ì—¼", "ì—ë„ˆì§€",
    "ì§€ì†ê°€ëŠ¥", "ESG", "CDP", "TCFD", "SBTi", "ë…¹ìƒ‰",
    # S (ì‚¬íšŒ)
    "ì‚¬íšŒ", "ì¸ê¶Œ", "ë…¸ë™", "ì•ˆì „", "ë³´ê±´", "ë‹¤ì–‘ì„±", "í¬ìš©", "ê³µê¸‰ë§", "í˜‘ë ¥ì‚¬",
    "ì§€ì—­ì‚¬íšŒ", "ì‚¬íšŒê³µí—Œ", "DEI", "ê·¼ë¡œì", "ê³ ìš©",
    # G (ì§€ë°°êµ¬ì¡°)
    "ì§€ë°°êµ¬ì¡°", "ì´ì‚¬íšŒ", "ì£¼ì£¼", "íˆ¬ëª…ì„±", "ê³µì‹œ", "ìœ¤ë¦¬", "ë°˜ë¶€íŒ¨", "ì»´í”Œë¼ì´ì–¸ìŠ¤",
    "ê±°ë²„ë„ŒìŠ¤", "ê°ì‚¬", "ë‚´ë¶€í†µì œ", "ë¦¬ìŠ¤í¬ê´€ë¦¬",
    # ì¼ë°˜ ESG
    "ESG", "ì§€ì†ê°€ëŠ¥ê²½ì˜", "ì‚¬íšŒì ì±…ì„", "CSR", "CSV", "ì„íŒ©íŠ¸", "ìŠ¤íŠœì–´ë“œì‹­",
]


def _is_esg_related(news: Dict) -> bool:
    """ë‰´ìŠ¤ê°€ ESGì™€ ê´€ë ¨ìˆëŠ”ì§€ í™•ì¸

    Args:
        news: ë‰´ìŠ¤ ë”•ì…”ë„ˆë¦¬

    Returns:
        bool: ESG ê´€ë ¨ ì—¬ë¶€
    """
    title = news.get("title", "").lower()
    summary = news.get("summary", "").lower()
    category = news.get("category", "").lower()

    text = f"{title} {summary} {category}"

    for keyword in ESG_KEYWORDS:
        if keyword.lower() in text:
            return True

    return False


def _filter_esg_news(news_list: List[Dict]) -> List[Dict]:
    """ESG ê´€ë ¨ ë‰´ìŠ¤ë§Œ í•„í„°ë§

    Args:
        news_list: ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸

    Returns:
        List[Dict]: ESG ê´€ë ¨ ë‰´ìŠ¤ë§Œ í¬í•¨ëœ ë¦¬ìŠ¤íŠ¸
    """
    filtered = [news for news in news_list if _is_esg_related(news)]
    removed_count = len(news_list) - len(filtered)

    if removed_count > 0:
        logger.info(f"ESG ê´€ë ¨ ì—†ëŠ” ë‰´ìŠ¤ {removed_count}ê±´ í•„í„°ë§ë¨")

    return filtered


def supervise_collection(state: ESGTrendsState) -> Dict:
    """ìˆ˜ì§‘ ë°ì´í„° í†µí•© ë° ë¶„ì„

    Args:
        state: í˜„ì¬ ìƒíƒœ

    Returns:
        Dict: ì—…ë°ì´íŠ¸í•  ìƒíƒœ í•„ë“œ
    """
    logger.info("ìˆ˜í¼ë°”ì´ì € ë¶„ì„ ì‹œì‘")

    # ìˆ˜ì§‘ëœ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    weather_data = state.get("weather_data", [])
    physical_risks = state.get("physical_risks", [])
    domestic_news = state.get("domestic_news", [])
    global_news = state.get("global_news", [])

    # ESG ê´€ë ¨ ë‰´ìŠ¤ë§Œ í•„í„°ë§
    domestic_news = _filter_esg_news(domestic_news)
    global_news = _filter_esg_news(global_news)

    # ë‚ ì”¨ ìš”ì•½ ìƒì„±
    weather_summary = _create_weather_summary(weather_data, physical_risks)

    # ESG ë‰´ìŠ¤ í†µí•©
    all_news = domestic_news + global_news

    if not all_news:
        logger.warning("ë¶„ì„í•  ESG ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
        return {
            "weather_summary": weather_summary,
            "domestic_news": domestic_news,
            "global_news": global_news,
            "esg_insight": "ìˆ˜ì§‘ëœ ESG ë‰´ìŠ¤ê°€ ì—†ì–´ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "trending_topics": [],
            "sudden_changes": [],
            "recommendations": [],
            "competitor_analysis": "",
        }

    # LLMì„ ì‚¬ìš©í•œ ESG ì¸ì‚¬ì´íŠ¸ ë¶„ì„
    try:
        llm = ChatOpenAI(
            model=Config.OPENAI_MODEL,
            temperature=0.3,
            api_key=Config.OPENAI_API_KEY,
        )

        # ë‰´ìŠ¤ ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„±
        news_text = _format_news_for_analysis(all_news)

        # ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±
        analysis_prompt = SUPERVISOR_ANALYSIS_PROMPT.format(
            news_count=len(all_news),
            domestic_count=len(domestic_news),
            global_count=len(global_news),
            news_text=news_text,
        )

        messages = [
            SystemMessage(content=SUPERVISOR_SYSTEM_PROMPT),
            HumanMessage(content=analysis_prompt),
        ]

        response = llm.invoke(messages)
        analysis_result = response.content

        # ë¶„ì„ ê²°ê³¼ íŒŒì‹±
        parsed = _parse_analysis_result(analysis_result)

        logger.info("ESG ì¸ì‚¬ì´íŠ¸ ë¶„ì„ ì™„ë£Œ")

        return {
            "weather_summary": weather_summary,
            "domestic_news": domestic_news,
            "global_news": global_news,
            "esg_insight": parsed.get("insight", analysis_result),
            "trending_topics": parsed.get("trending_topics", []),
            "sudden_changes": parsed.get("sudden_changes", []),
            "recommendations": parsed.get("recommendations", []),
            "competitor_analysis": parsed.get("competitor_analysis", ""),
        }

    except Exception as e:
        logger.error(f"LLM ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {
            "weather_summary": weather_summary,
            "domestic_news": domestic_news,
            "global_news": global_news,
            "esg_insight": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
            "trending_topics": [],
            "sudden_changes": [],
            "recommendations": [],
            "competitor_analysis": "",
            "errors": [f"ìˆ˜í¼ë°”ì´ì € ë¶„ì„ ì˜¤ë¥˜: {str(e)}"],
        }


def _create_weather_summary(weather_data: List[Dict], physical_risks: List[Dict]) -> str:
    """ë‚ ì”¨ ë°ì´í„° ìš”ì•½ ìƒì„±

    Args:
        weather_data: ë‚ ì”¨ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        physical_risks: ë¬¼ë¦¬ì  ë¦¬ìŠ¤í¬ ë¶„ì„ ê²°ê³¼

    Returns:
        str: ë‚ ì”¨ ìš”ì•½ í…ìŠ¤íŠ¸
    """
    if not weather_data:
        return "ë‚ ì”¨ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    summary_parts = []

    for data in weather_data:
        location = data.get("location", "ì•Œ ìˆ˜ ì—†ìŒ")
        temp = data.get("temperature", "N/A")
        condition = data.get("weather_condition", "")
        humidity = data.get("humidity", "N/A")

        summary_parts.append(
            f"ğŸ“ {location}: {temp}Â°C, {condition}, ìŠµë„ {humidity}%"
        )

    # ë¬¼ë¦¬ì  ë¦¬ìŠ¤í¬ ìš”ì•½
    high_risks = [r for r in physical_risks if r.get("risk_level") == "ë†’ìŒ"] if physical_risks else []
    medium_risks = [r for r in physical_risks if r.get("risk_level") == "ë³´í†µ"] if physical_risks else []

    if physical_risks and (high_risks or medium_risks):
        summary_parts.append("")  # ë¹ˆ ì¤„
        if high_risks:
            for risk in high_risks:
                summary_parts.append(f"ğŸ”´ {risk.get('risk_type')}: {risk.get('description')}")
        if medium_risks:
            for risk in medium_risks:
                summary_parts.append(f"ğŸŸ¡ {risk.get('risk_type')}: {risk.get('description')}")

    # ì¢…í•© ë¦¬ìŠ¤í¬ í‰ê°€ (ë§¨ ì•„ë˜)
    summary_parts.append("")  # ë¹ˆ ì¤„
    risk_assessment = _generate_risk_assessment(weather_data, high_risks, medium_risks)
    summary_parts.append(risk_assessment)

    return "\n".join(summary_parts)


def _generate_risk_assessment(weather_data: List[Dict], high_risks: List, medium_risks: List) -> str:
    """ë¬¼ë¦¬ì  ë¦¬ìŠ¤í¬ ì¢…í•© í‰ê°€ ìƒì„±

    Args:
        weather_data: ë‚ ì”¨ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        high_risks: ê³ ìœ„í—˜ ë¦¬ìŠ¤í¬ ë¦¬ìŠ¤íŠ¸
        medium_risks: ì¤‘ê°„ ìœ„í—˜ ë¦¬ìŠ¤í¬ ë¦¬ìŠ¤íŠ¸

    Returns:
        str: ì¢…í•© í‰ê°€ í…ìŠ¤íŠ¸
    """
    # í‰ê·  ê¸°ì˜¨ ê³„ì‚°
    temps = [d.get("temperature", 0) for d in weather_data if d.get("temperature") is not None]
    avg_temp = sum(temps) / len(temps) if temps else None

    # ë¦¬ìŠ¤í¬ ë ˆë²¨ íŒë‹¨
    if high_risks:
        risk_level = "ë†’ì€ í¸"
        risk_emoji = "âš ï¸"
    elif medium_risks:
        risk_level = "ë³´í†µ"
        risk_emoji = "ğŸ”¶"
    else:
        risk_level = "ë‚®ì€ í¸"
        risk_emoji = "âœ…"

    # ê³„ì ˆ/ê¸°ì˜¨ ê¸°ë°˜ ê¶Œê³ ì‚¬í•­
    if avg_temp is not None:
        if avg_temp <= 0:
            season_advice = "ê²¨ìš¸ì²  í•œíŒŒ ëŒ€ë¹„ í•„ìš”"
        elif avg_temp <= 10:
            season_advice = "ìŒ€ìŒ€í•œ ë‚ ì”¨ë¡œ ë‚œë°© ê´€ë¦¬ ì ê²€ ê¶Œì¥"
        elif avg_temp >= 33:
            season_advice = "í­ì—¼ ì£¼ì˜, ëƒ‰ë°© ë° ê·¼ë¡œì ê±´ê°•ê´€ë¦¬ í•„ìš”"
        elif avg_temp >= 28:
            season_advice = "ë”ìš´ ë‚ ì”¨ë¡œ ëƒ‰ë°© ê´€ë¦¬ ì ê²€ ê¶Œì¥"
        else:
            season_advice = "ì˜¨í™”í•œ ë‚ ì”¨ë¡œ íŠ¹ë³„í•œ ì¡°ì¹˜ ë¶ˆí•„ìš”"
    else:
        season_advice = "ë‚ ì”¨ ë°ì´í„° í™•ì¸ í•„ìš”"

    return f"{risk_emoji} í˜„ì¬ ë¬¼ë¦¬ì  ê¸°í›„ ë¦¬ìŠ¤í¬ëŠ” {risk_level}ì´ë©°, {season_advice}"


def _format_news_for_analysis(news_list: List[Dict]) -> str:
    """ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶„ì„ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

    Args:
        news_list: ESG ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸

    Returns:
        str: ë¶„ì„ìš© í…ìŠ¤íŠ¸
    """
    formatted = []

    for i, news in enumerate(news_list[:20], 1):  # ìµœëŒ€ 20ê°œ
        title = news.get("title", "")
        summary = news.get("summary", "")[:200]  # ìš”ì•½ì€ 200ìë¡œ ì œí•œ
        source = news.get("source", "")
        region = news.get("region", "")
        category = news.get("category", "")

        formatted.append(
            f"{i}. [{category}] {title}\n"
            f"   ì¶œì²˜: {source} | ì§€ì—­: {region}\n"
            f"   ìš”ì•½: {summary}"
        )

    return "\n\n".join(formatted)


def _parse_analysis_result(result: str) -> Dict:
    """LLM ë¶„ì„ ê²°ê³¼ íŒŒì‹±

    Args:
        result: LLM ì‘ë‹µ í…ìŠ¤íŠ¸

    Returns:
        Dict: íŒŒì‹±ëœ ê²°ê³¼
    """
    import re

    parsed = {
        "insight": result,
        "trending_topics": [],
        "sudden_changes": [],
        "recommendations": [],
        "competitor_analysis": "",
    }

    # ì„¹ì…˜ë³„ ë‚´ìš© ì¶”ì¶œì„ ìœ„í•œ ì •ê·œì‹
    sections = {
        "insight": r"(?:##?\s*)?(?:ì£¼ìš”\s*)?ì¸ì‚¬ì´íŠ¸[^\n]*\n([\s\S]*?)(?=##|$)",
        "trending": r"(?:##?\s*)?íŠ¸ë Œë“œ\s*í‚¤ì›Œë“œ[^\n]*\n([\s\S]*?)(?=##|$)",
        "changes": r"(?:##?\s*)?ê¸‰ë³€\s*ê°ì§€[^\n]*\n([\s\S]*?)(?=##|$)",
        "recommendations": r"(?:##?\s*)?ê¶Œê³ \s*ì‚¬í•­[^\n]*\n([\s\S]*?)(?=##|$)",
        "competitor": r"(?:##?\s*)?ê²½ìŸì‚¬[/|]?ì—…ê³„\s*ë™í–¥[^\n]*\n([\s\S]*?)(?=##|$)",
    }

    # ê° ì„¹ì…˜ ì¶”ì¶œ
    for section_key, pattern in sections.items():
        match = re.search(pattern, result, re.IGNORECASE)
        if match:
            content = match.group(1).strip()

            if section_key == "insight":
                parsed["insight"] = content if content else result
            elif section_key == "competitor":
                parsed["competitor_analysis"] = content
            else:
                # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ì„¹ì…˜ì€ bullet point ì¶”ì¶œ
                items = []
                for line in content.split("\n"):
                    line = line.strip()
                    if line.startswith("- ") or line.startswith("â€¢ ") or line.startswith("* "):
                        items.append(line[2:].strip())
                    elif line.startswith("1.") or line.startswith("2.") or line.startswith("3."):
                        # ìˆ«ì ë¦¬ìŠ¤íŠ¸ë„ ì²˜ë¦¬
                        items.append(re.sub(r"^\d+\.\s*", "", line).strip())

                if section_key == "trending":
                    parsed["trending_topics"] = items
                elif section_key == "changes":
                    parsed["sudden_changes"] = items
                elif section_key == "recommendations":
                    parsed["recommendations"] = items

    # í´ë°±: ì •ê·œì‹ìœ¼ë¡œ ëª» ì°¾ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‹œë„
    if not parsed["trending_topics"] and not parsed["recommendations"]:
        lines = result.split("\n")
        current_section = None

        for line in lines:
            line = line.strip()
            if not line:
                continue

            if "íŠ¸ë Œë“œ" in line or "í‚¤ì›Œë“œ" in line:
                current_section = "trending"
            elif "ê¸‰ë³€" in line or "ë³€í™”" in line:
                current_section = "changes"
            elif "ê¶Œê³ " in line or "ì¶”ì²œ" in line:
                current_section = "recommendations"
            elif "ê²½ìŸ" in line or "ë²¤ì¹˜ë§ˆí¬" in line or "ì—…ê³„" in line:
                current_section = "competitor"
            elif line.startswith("- ") or line.startswith("â€¢ ") or line.startswith("* "):
                item = line[2:].strip()
                if current_section == "trending":
                    parsed["trending_topics"].append(item)
                elif current_section == "changes":
                    parsed["sudden_changes"].append(item)
                elif current_section == "recommendations":
                    parsed["recommendations"].append(item)
            elif current_section == "competitor" and not line.startswith("#"):
                # ê²½ìŸì‚¬ ë¶„ì„ì€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ í…ìŠ¤íŠ¸ì¼ ìˆ˜ ìˆìŒ
                if parsed["competitor_analysis"]:
                    parsed["competitor_analysis"] += "\n" + line
                else:
                    parsed["competitor_analysis"] = line

    return parsed
